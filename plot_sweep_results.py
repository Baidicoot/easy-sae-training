import itertools
import math
import os
import shutil
from typing import List, Tuple, Dict, Any

import matplotlib
import matplotlib.pyplot as plt
from matplotlib.markers import MarkerStyle
from matplotlib.lines import Line2D
import numpy as np
import torch
import tqdm

from autoencoders.pca import BatchedPCA, PCAEncoder
from autoencoders.learned_dict import LearnedDict
import standard_metrics


def plot_by_group() -> None:
    chunk_range = [9]
    learned_dict_files = [os.path.join("/mnt/ssd-cluster/bigrun0308", x) for x in os.listdir("/mnt/ssd-cluster/bigrun0308")]
    learned_dict_files += [f for f in os.listdir(".") if f.startswith("output_attn")]
    learned_dict_files += [f for f in os.listdir(".") if f.startswith("output_sweep")]

    resid_dicts = [f for f in learned_dict_files if "resid" in f]
    mlp_dicts = [f for f in learned_dict_files if "mlp" in f]
    mlp_dicts = [f for f in mlp_dicts if "mlp_out" not in f]
    attn_dicts = [f for f in learned_dict_files if "attn" in f]
    mlp_out_dicts = [f for f in learned_dict_files if "mlp_out" in f]

    layer_0_dicts = [f for f in learned_dict_files if "l0" in f]
    layer_1_dicts = [f for f in learned_dict_files if "l1" in f]
    layer_2_dicts = [f for f in learned_dict_files if "l2" in f]
    layer_3_dicts = [f for f in learned_dict_files if "l3" in f]
    layer_4_dicts = [f for f in learned_dict_files if "l4" in f]
    layer_5_dicts = [f for f in learned_dict_files if "l5" in f]

    ratio0_5_dicts = [f for f in learned_dict_files if "r0" in f]
    ratio1_dicts = [f for f in learned_dict_files if "r1" in f]
    ratio2_dicts = [f for f in learned_dict_files if "r2" in f]
    ratio4_dicts = [f for f in learned_dict_files if "r4" in f]
    ratio8_dicts = [f for f in learned_dict_files if "r8" in f]
    ratio16_dicts = [f for f in learned_dict_files if "r16" in f]
    ratio32_dicts = [f for f in learned_dict_files if "r32" in f]

    tied_dicts = [f for f in learned_dict_files if "tied" in f]
    untied_dicts = [f for f in learned_dict_files if not "tied" in f]

    # experiments = [
    #     ("l0_resid", [layer_0_dicts, resid_dicts]),
    #     ("l1_resid", [layer_1_dicts, resid_dicts]),
    #     ("l2_resid", [layer_2_dicts, resid_dicts]),
    #     ("l3_resid", [layer_3_dicts, resid_dicts]),
    #     ("l4_resid", [layer_4_dicts, resid_dicts]),
    #     ("l5_resid", [layer_5_dicts, resid_dicts]),
    #     ("l0_mlp", [layer_0_dicts, mlp_dicts]),
    #     ("l1_mlp", [layer_1_dicts, mlp_dicts]),
    #     ("l2_mlp", [layer_2_dicts, mlp_dicts]),
    #     ("l3_mlp", [layer_3_dicts, mlp_dicts]),
    #     ("l4_mlp", [layer_4_dicts, mlp_dicts]),
    #     ("l5_mlp", [layer_5_dicts, mlp_dicts]),
    # ]
    experiments = [
        ("l0_mlp_out", [[layer_0_dicts, mlp_out_dicts]]),
        ("l1_mlp_out", [[layer_1_dicts, mlp_out_dicts]]),
        ("l2_mlp_out", [[layer_2_dicts, mlp_out_dicts]]),
        ("l3_mlp_out", [[layer_3_dicts, mlp_out_dicts]]),
        ("l4_mlp_out", [[layer_4_dicts, mlp_out_dicts]]),
        ("l5_mlp_out", [[layer_5_dicts, mlp_out_dicts]]),
    ]

    for graph_name, categories in experiments:
        learned_dicts_nested: List[List[Tuple[str, List[Tuple[LearnedDict, Dict[Any, Any]]]]]] = []
        for subcategory in categories:
            learned_dict_loc_list = list(set.intersection(*[set(x) for x in subcategory]))
            learned_dict_loc_list.sort(key=lambda x: int(x.split("_")[-1][1:])) # sort by ratio
            learned_dict_lists = [(x.split("sweep_")[-1], torch.load(os.path.join(x, "_4", "learned_dicts.pt"))) for x in learned_dict_loc_list]
            learned_dicts_nested.append(learned_dict_lists)

        print(f"Found {sum(len(x) for x in learned_dicts_nested)} lists of dicts for experiment {graph_name}")

        dataset = torch.load(f"/mnt/ssd-cluster/single_chunks/{graph_name}/0.pt")
        sample_idxs = np.random.choice(len(dataset), 5000, replace=False)

        device = torch.device("cuda:0")

        sample = dataset[sample_idxs].to(dtype=torch.float32, device=device)

        all_data: List[List[Tuple[str, List[Tuple[float, float, float]]]]] = []
        for learned_dict_list in learned_dicts_nested:
            datapoint_series: List[Tuple[str, List[Tuple[float, float, float]]]] = []
            for run_name, learned_dict_set in learned_dict_list:
                datapoints: List[Tuple[float, float, float]] = []
                for learned_dict, hyperparams in learned_dict_set:
                    learned_dict.to_device(device)
                    r_sq = standard_metrics.fraction_variance_unexplained(learned_dict, sample).item()
                    sparsity = standard_metrics.mean_nonzero_activations(learned_dict, sample).sum().item()
                    datapoints.append((r_sq, sparsity, hyperparams["l1_alpha"]))
                datapoint_series.append((run_name, datapoints))
            all_data.append(datapoint_series)

        colors = ["Purples", "Blues", "Greens", "Oranges", "Reds", "Greys", "YlOrBr", "YlOrRd", "OrRd"]
        markers = ["o", "v", "s", "P", "X"]
        #labels = ["0.5", "1", "2", "4", "8"]
        #labels = [str(r) for r in learned_dict_files]

        fig = plt.figure()
        ax = fig.add_subplot(111)
        for k, datapoint_lists in enumerate(all_data):
            for i, (run_name, datapoints) in enumerate(datapoint_lists):
                r_sq, sparsity, l1_alpha = zip(*datapoints)
                ax.scatter(sparsity, r_sq, c=[math.log10(l1) for l1 in l1_alpha], label=run_name, cmap=colors[i % len(colors)], vmin=-5, vmax=-2, marker=markers[k % len(markers)])
                if i == len(datapoints) - 1:
                    # write the l1_alpha values on every 5th point and highlight them
                    for j, (x, y) in enumerate(zip(sparsity, r_sq)):
                        if j % 5 == 0:
                            ax.annotate(f"{l1_alpha[j]:.1}", (x, y))
                            ax.scatter([x], [y], c="black")

        # cap the x axis at 512, but allow smaller
        l, r = ax.get_xlim()
        ax.set_xlim(0, min(r, 512))
        ax.set_ylim(0, 1)
        
        ax.set_xlabel("Mean no. features active")
        ax.set_ylabel("Unexplained Variance")
        ax.legend()
        plt.savefig(f"freq_plot_compare_{graph_name}_5.png")
        print(f"Saved plot for {graph_name}")


def plot_fuv_sparsity():
    learned_dict_files = [
        #"output_4_rd_deep/_0/learned_dicts.pt",
        #"output_4_rd_deep/_1/learned_dicts.pt",
        #"output_4_rd_deep/_2/learned_dicts.pt",
        #"output_4_rd_deep/_3/learned_dicts.pt",
        #"output_4_rd_deep/_4/learned_dicts.pt",
        #"output_4_rd_deep/_5/learned_dicts.pt",
        #"output_4_rd_deep/_6/learned_dicts.pt",
        #"output_4_lista/_7/learned_dicts.pt",
        # "output_4_lista_deep/_7/learned_dicts.pt",
        #"output_4_lista_neg/_7/learned_dicts.pt",
        #"output_4_rd_deep/_7/learned_dicts.pt",
        #"output_4_tied/_7/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r1/_9/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r2/_9/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r4/_9/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r8/_9/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r16/_9/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r32/_9/learned_dicts.pt",
        #"output_topk/_27/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r0/_9/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r2/_9/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r8/_9/learned_dicts.pt",
        #"/mnt/ssd-cluster/bigrun0308/output_hoagy_dense_sweep_tied_resid_l2_r16/_9/learned_dicts.pt",
        "output_topk_synthetic/_49/learned_dicts.pt",
        "output_tied_synthetic/_49/learned_dicts.pt",
    ]

    ground_truth_file = "output_topk_synthetic/generator.pt"

    ground_truth = torch.load(ground_truth_file).sparse_component_dict.to("cuda:7")

    file_labels = [
        "TopK",
        "Tied Linear",
    ]

    learned_dict_sets = {}

    for label, learned_dict_file in zip(file_labels, learned_dict_files):
        learned_dicts = torch.load(learned_dict_file)
        dict_sizes = list(set([hyperparams["dict_size"] for _, hyperparams in learned_dicts]))
        for learned_dict, hyperparams in learned_dicts:
            name = label + " " + str(hyperparams["dict_size"])

            if name not in learned_dict_sets:
                learned_dict_sets[name] = []
            learned_dict_sets[name].append((learned_dict, hyperparams))

    device = torch.device("cuda:7")

    dataset = torch.load("activation_data_synthetic/0.pt").to(dtype=torch.float32, device=device)
    
    pca = BatchedPCA(dataset.shape[1], device)

    """
    datapoint = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]], dtype=torch.float32)
    pca_test = PCAEncoder(torch.eye(datapoint.shape[1]), 2)
    print(pca_test.encode(datapoint))
    code = pca_test.encode(datapoint)
    print(pca_test.predict(code))
    """

    print("Training PCA")

    batch_size = 5000
    for i in tqdm.tqdm(range(0, len(dataset), batch_size)):
        j = min(i + batch_size, len(dataset))
        batch = dataset[i:j]
        pca.train_batch(batch)
    
    sample_idxs = np.random.choice(len(dataset), 50000, replace=False)
    sample = dataset[sample_idxs]

    del dataset

    print("Scoring PCA")

    pca_scores = []
    for sparsity in tqdm.tqdm(range(1, sample.shape[1] // 2, 4)):
        pca_dict = pca.to_learned_dict(sparsity)
        #pca_dict = PCAEncoder(torch.eye(sample.shape[1], device=device), sparsity)
        fvu = standard_metrics.fraction_variance_unexplained(pca_dict, sample).item()
        pca_scores.append((sparsity, fvu))

    #means = []
    #variances = []
    #datapoints = []
    scores = {}
    for label, learned_dict_set in learned_dict_sets.items():
        #points = []
        scores[label] = []
        for learned_dict, hyperparams in learned_dict_set:
            learned_dict.to_device(device)
            fvu = standard_metrics.fraction_variance_unexplained(learned_dict, sample).item()
            sparsity = standard_metrics.mean_nonzero_activations(learned_dict, sample).sum().item()
            mcs = standard_metrics.mmcs_to_fixed(learned_dict, ground_truth).item()
            scores[label].append((sparsity, fvu, mcs))

    colors = ["Purples", "Blues", "Greens", "Oranges"]
    markers = ["o", "x", "s", "P", "v"]
    styles = ["dotted", "dashdot", "solid", "dashdot"]
    settings = itertools.product(styles, colors)

    os.makedirs("graphs", exist_ok=True)
    shutil.rmtree("graphs")
    os.makedirs("graphs", exist_ok=True)

    """
    l1_vals = sorted(list(set([l1 for _, l1, _ in means])))
    dict_sizes = sorted(list(set([d for _, _, d in means])))

    mean_img = np.zeros((len(l1_vals), len(dict_sizes)))
    var_img = np.zeros((len(l1_vals), len(dict_sizes)))

    for mean, l1, dict_size in means:
        mean_img[l1_vals.index(l1), dict_sizes.index(dict_size)] = mean
    
    for var, l1, dict_size in variances:
        var_img[l1_vals.index(l1), dict_sizes.index(dict_size)] = var
    
    fig = plt.figure()
    ax = fig.add_subplot(111)
    img = ax.imshow(mean_img.T, cmap="plasma")
    ax.set_yticks(range(len(dict_sizes)))
    ax.set_yticklabels(dict_sizes)
    ax.set_xticks(range(len(l1_vals)))
    ax.set_xticklabels([f"{l1_val:.2e}" for l1_val in l1_vals], rotation=90)
    ax.set_ylabel("Dictionary Size")
    ax.set_xlabel("l1_alpha")
    ax.set_title("Mean no. activations")
    fig.colorbar(img)
    plt.savefig("graphs/mean_activations.png")
    plt.close(fig)

    fig = plt.figure()
    ax = fig.add_subplot(111)
    img = ax.imshow(var_img.T, cmap="plasma")
    ax.set_yticks(range(len(dict_sizes)))
    ax.set_yticklabels(dict_sizes)
    ax.set_xticks(range(len(l1_vals)))
    ax.set_xticklabels([f"{l1_val:.2e}" for l1_val in l1_vals], rotation=90)
    ax.set_ylabel("Dictionary Size")
    ax.set_xlabel("l1_alpha")
    ax.set_title("Variance no. activations")
    fig.colorbar(img)
    plt.savefig("graphs/var_activations.png")
    plt.close(fig)

    for sparsity, clamped_sparsity, l1_alpha, dict_size in tqdm.tqdm(datapoints):
        fig = plt.figure()
        ax = fig.add_subplot(111)
        ax.hist(sparsity, bins=50)
        ax.set_yscale("log")
        ax.set_xlabel("Mean no. activations")
        ax.set_ylabel("Frequency")
        ax.set_title(f"l1_alpha={l1_alpha:.2e}, dict_size={dict_size}")
        plt.savefig(f"graphs/log_freq_plot_{l1_alpha:.2e}_{dict_size}.png")
        plt.close(fig)

        fig = plt.figure()
        ax = fig.add_subplot(111)
        ax.hist(clamped_sparsity, bins=50)
        ax.set_yscale("log")
        ax.set_xlabel("Mean no. activations")
        ax.set_ylabel("Frequency")
        ax.set_title(f"l1_alpha={l1_alpha:.2e}, dict_size={dict_size}")
        plt.savefig(f"graphs/log_freq_plot_clamped_{l1_alpha:.2e}_{dict_size}.png")
        plt.close(fig)
    """

    fig = plt.figure()
    ax = fig.add_subplot(111)
    legend_lines = []
    legend_names = []
    for (style, color), (label, series) in zip(settings, scores.items()):
        #cmap = matplotlib.cm.get_cmap(color)
        #norm = matplotlib.colors.Normalize(vmin=0, vmax=1)
        #colors_ = [cmap(norm(mcs)) for _, _, mcs in series]
        sorted_series = sorted(series, key=lambda x: x[0])
        sparsity, fvu, mcs = zip(*sorted_series)

        points = np.array([fvu, mcs]).T.reshape(-1, 1, 2)
        c = np.ones_like(np.array(mcs))
        segments = np.concatenate([points[:-1], points[1:]], axis=1)

        cs = 0.5 * (c[:-1] + c[1:])
        norm = matplotlib.colors.Normalize(vmin=0, vmax=1)
        cmap = matplotlib.cm.get_cmap(color)
        lc = matplotlib.collections.LineCollection(segments, cmap=cmap, norm=norm, linestyle=style)
        lc.set_array(cs)
        lc.set_linewidth(2)
        line = ax.add_collection(lc)

        legend_lines.append(Line2D([0], [0], color=cmap(0.5), linestyle=style, linewidth=2))
        legend_names.append(label)

        #ax.plot(sparsity, fvu, label=label, color=color, linestyle=style)

    #pca_xs = [s for s, _ in pca_scores]
    #pca_ys = [s for _, s in pca_scores]
    #ax.plot(pca_xs, pca_ys, color="red", linestyle="dashed")

    #legend_lines.append(Line2D([0], [0], color="red", linestyle="dashed"))
    #legend_names.append("PCA")

    ax.set_xlabel("Fraction Variance Unexplained")
    ax.set_ylabel("MCS")

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)

    ax.legend(legend_lines, legend_names)

    #ax.set_yscale("log")

    # fix legend colors
    #legend = ax.get_legend()
    #for i, l in enumerate(legend.legend_handles[:-1]):
    #    l.set_color(matplotlib.colormaps.get_cmap(colors[i % len(colors)])(0.8))

    plt.savefig("mcs_fvu.png")

    ax.set_yscale("log")

    plt.savefig("mcs_fvu_log.png")


if __name__ == "__main__":
    plot_by_group()
